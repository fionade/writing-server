Augmented Reality for Industrial Building Acceptance
ABSTRACT
In this paper we present an Augmented Reality (AR) application for industrial building acceptance. Building acceptance is the process of comparing as-planned documentation with the factory that was actually built. A self-supported mobile AR device, the AR-Planar, is used to facilitate this comparison by overlaying 3D models on top of a video image. The suitability of this approach is assessed using an expert heuristic in a real factory, and furthermore the usability of the AR-Planar in comparison to other AR systems was examined in a complementary user study.
CR Categories and Subject Descriptors: H.5.1 [Information interfaces and presentation]: Multimedia Information Systems - Artificial, augmented, and virtual realities; H.5.2 [Information interfaces and presentation]: User Interfaces; J.7 [Computers in other systems]: Industrial control.
Additional Keywords: ergonomics, user study, augmented reality
1 INTRODUCTION AND RELATED WORK
An important area for AR technology are industrial applications, where significant investments are at stake and improvements in work efficiency can return significant savings. Navab et al. [1] describe AR-assisted as-built documentation of industrial facilities as a “killer app”. Industrial applications at large - maintenance, assembly, construction, service, repair, training, factory planning - have received a lot of attention, in particular in the German ARVIKA research project [2].
The application investigated in this paper is augmented reality building acceptance (ARBA). Building acceptance in industry is the process of checking if a built structure is identical with the planned structure before final approval (and payment) is issued. Our project is not the first attempt at projecting digital models into a life-size environment. Introduced by [3] AR/VR architecture applications have been investigated e.g. to simulate reactions to environmental conditions [4] or to reveal hidden structures [5]. In [6] a mobile AR setup is used to re-create architectural structures by placing virtual walls into outdoor space.
The main contribution of this paper is the description of the ARBA application, offering insight into the details that made our solution not only technically sound but also a success in terms of real-world usage. ARBA has entered the operative state in a real industrial process. It is therefore relevant to compare ARBA to existing commercial approaches to building acceptance and discuss how ARBA fits into the overall process of industrial facility construction.
This paper also introduces the AR-Planar, a self-supported mobile AR device with a touch screen, which was designed for convenient operation for extended work periods. The AR-Planar
Figure 1. professional during AR building acceptance (ARBA) on factory floor using the AR-Planar
is based on the original Planar report in [7], which was designed for spatial interaction with CAD models. The AR-Planar extends the Planar with a video see-through mode and appropriate interaction techniques.
To back up the claims concerning ARBA, we report on the results of an heuristic evaluation that was conducted among the professional users after a successful building acceptance process on a 300 by 150 meter multistorey factory floor (Figure 1). Responses cover the AR system itself as well as the whole process it is integrated in. To verify our choice of user interface we also conducted an application-oriented user study aimed at comparing the usability of the AR-Planar versus a backpack system with a head-mounted display (HMD) and a handheld UMPC.
 2 2.1
DIGITAL FACTORY PLANNING AND BUILDING ACCEPTANCE Digital Factory Planning
Like digital product development, digital factory planning is a key strategy for reducing the time-to-market span of new commodities. Many products need complex manufacturing hardware, which has to be developed and placed according to the required production steps. This placement requires sufficient space and a suitable infrastructure, which is usually provided by the building in which the hardware is placed. To ensure that every required column, tube, robot, etc. is allocated an appropriate position, digital factory planning represents all items in a 3D model and checks for collisions and other irregularities. In this way most problems can be resolved before the physical factory construction and setup process starts.
  Street Address and Electronic Mail Address
 LEAVE 0.5 INCH SPACE AT BOTTOM OF LEFT COLUMN ON FIRST PAGE FOR COPYWRITE BLOCK

    Figure 2. industrial environment with complex architecture and infrastructure; screen is split vertically into three segments: on the left pure virtual model, on the right pure photograph, AR overlay in between
After construction starts, all work needs to be verified against the planning documents. Most of this process usually takes place during the construction phase. However, a more formal verification process takes place after a structure has been built. This process of building acceptance is due to the fact that usually those responsible for building a structure are different from the structure’s owners or designers. Building acceptance has two main goals: verifying whether the structure fulfils its desired function, but also finding differences between built and planned states that may not render a building unacceptable, but that can lower the value of the building, particularly in terms of reusability.
The problem of reusability mainly arises from 3D models which are not up to date so that later modifications in the factory structure or occupation cannot be reliably planned. This frequently brings about a significant loss of time and money. There are several approaches to solving this problem: the traditional option is verification by hand directly in the building, often with the help of geodetic devices and laser range finders. This procedure consumes a lot of skilled labour. Complex geometries as seen in Figure 2 are nearly impossible to judge in terms of validity. Therefore, a manual approach is limited to the verification of hotspots, i. e., regions of special interests, like tube crossings.
Alternatively, laser scans can be conducted, which lead to a new, as-built 3D model. Special devices generate point clouds from strategically chosen observer positions in the factory hall. Those point clouds are merged and later transformed into meaningful geometries. The obvious advantage is that it is possible to obtain a complete model, not only hotspots. The main drawback of this approach is that no full automation exists for the process of translating point clouds into geometric primitives that can be compared to the as-planned model. The semi-automatic translation again results in high costs for skilled labour.
2.2 Augmented reality for building acceptance
As an alternative to surveying or scanning, an AR approach to building acceptance (ARBA) can be chosen. An AR display superimposes the digital model directly onto a live image of the physical structure (Figure 2), thereby allowing in-situ comparison of as-planned and as-built. A skilled inspector should be able to quickly point out the geometric differences that may be critical in the future.
The AR assisted comparison can be performed offsite, e.g. with videos taken at the real building, and later overlaid with the spatial correctly aligned 3D model [8][9], or onsite, which means directly in the building. Both approaches have their advantages and drawbacks: offsite AR is minimally invasive with respect to a building that is already in use, but does not permit a choice of camera locations and orientations freely after the video has been captured. Some items which require closer inspection may not be covered well enough, resulting in another acquisition and processing cycle.
Onsite AR is technically more challenging and occupies space in the factory hall at least for the duration of the inspection.
Figure 3. ARBA process scheme
   
For stable tracking either calibrated stationary markers or outside-in tracking infrastructure are needed. The advantage of onsite AR lies in the ability to interactively inspect hotspots at any level of detail if desired. Moreover, stakeholders tend to accept differences better when confronted on the real site rather than with a pre-recorded video. These advantages led us to choose onsite ARBA as the method of choice.
2.3 Process Description
The overall process of ARBA is described in Figure 3 and can be broken up into the following segments: overall preparation; hotspot setup; building acceptance; hotspot dismantling; overall postprocessing. Steps D to T form the hotspot cycle and steps M to P the building acceptance cycle.
The process of ARBA is initiated by the project manager, who is responsible for the timely completion of a building structure. The manager is responsible for the planning personnel as well as for the contractors who perform the actual construction work. For the inspection, the manager then makes a list of hotspots suitable to ARBA inspection.
The hotspots are marked with two on-site reference points with six degrees of freedom (6DOF), acquired through geodetic surveying. Upon exporting the model from the CAD software to the ARBA application, the reference points are used to register the CAD data with the real factory environment. An “offline viewer” for immersive visualization (Powerwall) is also available.
After completing off-site preparations and arranging a suitable date for ARBA, which allows the ARBA team to work relatively undisturbed at the hotspots, the equipment – most importantly, the AR-Planar and the four tripod-mounted tracking cameras – is transported to the site of the first hotspot. The tracking cameras are set up around the previously surveyed reference points. This allows the coordinates systems of tracking and 3D model to be registered to real-world coordinates. If misregistration between model and real world occurs, the user can manually adjust a static offset.
The actual building acceptance process works by repeatedly navigating the AR-Planar to aim its video camera at the desired regions of interest. By changing the visual properties of the model data and the video overlay, differences can be spotted. Observed artefacts can be immediately annotated using the stylus. View and current pose in the model are saved for offline documentation (Figure 4).
Figure 4. documentation from ARBA, here the AR screenshot with annotation; a pure virtual and a pure video screen of
this scene are additionally saved
When the inspector is satisfied with the examination of the current hotspot, the portable infrastructure is moved to the next hotspot, and so on until all scheduled hotspots have been visited. In an offline post processing step the documentation data gathered from ARBA is assembled into a report containing additional instructions. That report is now sent to the responsible contractors, who will in return have to deliver revised 3D data.
3 IMPLEMENTATION 3.1 AR-Planar
The original planar reported in [7] was conceived as a hybrid between a CAD workstation and a spatial interaction device. It uses a high resolution touch screen suspended on a mechanical arm with a large number of degrees of freedom. The objective was to design a physical user interface that blends into existing CAD work practices, yet which can deliver spatial interaction on demand. The Planar’s “window in hand” metaphor is inspired by [10], and several related devices exist [11], [12], [13], [14] for VR interaction. However, AR interfaces differ significantly in operation insofar as the device has to be moved in a physical environment to yield the desired view. The only self-supported AR device that fits this definition is the Augurscope [15], which was designed primarily for outdoor use and employs a touch screen instead of a pen-based display but otherwise is the AR- Planar’s closest sibling.
The AR-Planar (Figure 5) uses a pen tablet display (Wacom Cintiq 18SX) operated with a stylus. The display can be turned and tiled, and the height can be adjusted using a telescope mechanism. All joints and movable parts can be latched. This makes it possible to write on the display without having to hold it with the other hand, unlike e.g. the Boom Chameleon device. The construction is counterbalanced and supported by ball bearings, so that little force is required. The bottom part leaves space for resting ones feet, and is supported by four wheels for convenient repositioning.
The AR-Planar uses a video feed from a camera attached to the display through a tiltable joint, increasing the maximum possible tilt angle beyond what is supported by the display. In the ARBA application, the video image was placed semi-transparently in front of the geometry – unlike most other AR displays, the observer is not interested in the fusion of virtual objects with the real world. Instead, the interest is in comparing all visible items from the real world with all visible items of the virtual world,
   
Figure 5. technical properties of AR-Planar (left) and current development state (right)
Figure 6. description of ScrewDragger interface, which is used to move selected objects
assuming the same viewpoint. Thus, an adjustable transparency of the front plane bearing the video image determines the degree of augmentation, rather than the transparency of a virtual object.
To obtain the most accurate registration, the video plane is rendered using warping to compensate for the intrinsic camera parameters of the video camera, obtained using the method in [16]. The CAD models, which can be very large, are rendered efficiently using an occlusion renderer [17].
3.2 Interaction
The interaction with the AR-Planar is inspired by stylus- operated CAD systems. The user can sketch annotations with the stylus in the AR overlay view and use a 2D interface on the right to adjust the transparency of the video overlay, change the far clipping plane (constrain depth complexity) and trigger function such as screenshots.
For the manipulation of 3D objects, a double click with the stylus selects a a virtual object and summons a ScrewDragger
interface. The ScrewDragger interface was developed for the translation of objects along one axis in world coordinates at a time. The use of this special manipulation interface is based on the observation that most objects in building models we examined are aligned to the world coordinate axes.
The ScrewDragger consists of four directional arrows for the left, right, up and down directions, and two surrounding circular arrows oriented in clockwise and counterclockwise direction, resembling the tilt of the thread of a screw. The widget is oriented in such a way that it aligns with the world coordinate axes but still keeps the directional arrows as flat as possible to the surface.
Dragging one of the directional arrows (the dragger stays put) moves the associated object along that axis. In order to translate the object in the remaining ”depth” direction, the user points at one of the round arrows and performs a dragging motion resembling stirring a glass of water. The associated object is translated in the depth direction, like a screw getting moved down when it is turned (Figure 6).
3.3 Tracking
A custom version of the ART Qualisys 1 [18] tracking system is used for real-time tracking of the AR display. The tracking system is optimized for fast deployment with the objective of checking several hotspots within a short timeframe. Optimizations include the utilization of WiFi for communication among system components, independent power supplies, and special tripod camera mounts.
Extrinsic registration is accomplished by aligning the camera axis along the tracking system’s x-axis and keeping the up-vector upright in that process. Then the target is calibrated. Thus, the target mounted to the camera will always deliver world orientation, when the room calibration process places the tracking coordinate system congruently to the world coordinate system. Finally, the used 3D user data must simply be translated towards the right position. This position is calculated by using a given reference point from geodetic acquisition and the offset from the tracking origin towards this point.
In situations where the reference points are missing or badly placed, users are still able to set up the system manually:
  Figure 7. picture taken from the ARBA field trial; the four tracking tripods can be seen on the left and right sides of the picture; professionals work with the AR-Planar in the middle of the picture

assuming that orientations between real and virtual world are aligned by exploiting the rectangular building outline, the missing translational part can be acquired by user interaction. This task requires an experienced eye as well as some landmarks (e.g. columns) that are placed in orthogonal directions. The user looks at one landmark and translates the scene to the best matching spot. Then he/she turns 90 degrees left/right/up/down and adjusts according to a second landmark. By repeating those steps a reasonably precise guess of the translational offset between real and virtual worlds can be acquired. This procedure was sometimes used for fine adjustments.
3.4 Accuracy
There are limitations of ARBA to what a user can and should judge when comparing real-word and virtual geometries. Camera opening angle and resolution in combination with the distance to the reviewed object determine the theoretical precision that a person can use to draw conclusions. Assuming a camera system with a horizontal opening angle of 70° and a horizontal resolution of 800 pixels, at a distance of 2 meters one pixel has a horizontal stretch of ~3.5 mm, at 10 meters the stretch is already 1.75 cm,
growing linearly with distance.
The Qualisys tracking system is specified with a maximum
orientation error of 0.4°, which results in a possible visual deviation of ~7 cm at 10 meters distance. Assuming that the intrinsic camera calibration delivers a maximum error of one pixel, no user should report a 10 cm difference between the model data and the real world structures when being positioned 10 m away.
Fortunately, in the cases examined in this paper, the building acceptance process does not require this level of precision. Building tolerance is normally given at 5 cm, and the most important errors are well beyond that magnitude.
4 FIELD TRIAL
We conducted a two-day long building acceptance with the ARBA system, carried out by three professionals who deal with the issues of digital factory construction on a daily basis (Figure 7). To record their comments and critique, we interviewed them during the process, protocolled emerging issues, and also conducted a heuristic evaluation in the aftermath.
The way of doing the building acceptance with the Planar
   Stage
       Problem Solution
      Preparation
An important issue in the preparation process is the placing of reference points. As this task is performed by a third party that is not involved in ARBA, there is a lack of knowledge about the optimal placement of the reference points in relation to the selected hotspot
    Provide better guidelines for the placement of reference points
     Preparation
 The reference points were not durable enough. The wheels of factory traffic erased some of the points, which were marked by stickers.
    Use small carvings instead of stickers
     Preparation
  The ARBA model did not contain the responsible contractors per object, which would be useful to speed up the annotation of identified problems.
     Include contractor info
     Setup
A large issue deals with the number and weight of the required equipment parts. The camera tripods are mounted on wheels, but weigh 300kg each. Because of the significant weight they were supposed to be carried around by fork-lift trucks, but this option was not always available. Thus, the ARBA operators had to manually move the tripods.
    Provide fork-lift trucks or other solution to move equipment
     Setup
 The tracking system’s calibration process was perceived as complicated by the professionals.
    Better guidelines or an automatic calibration procedure required
     Setup
  The adjustment of the tracking camera’s viewing angle required a violation of workplace safety rules, as the professionals have to climb the tripods.
     Remote controlled pan-tilt units for tripods (expensive)
     Setup
The professionals also desired a one-button control for starting the overall system. The current solution required to start several devices and software components manually.
    Add one-button control
     Building Acceptance
 An online help system in the style of common desktop applications was missed in ARBA.
    Add online help
     Building Acceptance
  For general orientation, a map of the region was missing inside the application software.
     Add a map view that is interchangeable with the AR view.
     Building Acceptance
There is no warning when leaving the tracked area.
    Provide an acoustic signal or display the quality of tracking within the GUI.
     Building Acceptance
  Concerning the AR display, similar colors may occur in the model and the video image, which makes it hard to distinguish the relevant items.
     Add hotkeys for switching color schemes
     Building Acceptance
The ability to tilt the AR camera separately from the overall display tilt was sometimes not obvious or forgotten, leading to futile attempts to tilt the display itself beyond its 90 degree tilt radius were undertaken.
    Add a sensor which detects over-tilting attempts and prompts user to tilt camera rather than display
     Building Acceptance
  The function for switching the visibility of model parts is hidden in a system menu.
     Provide a better user interface for that function
     Post- processing
One complaint concerned the missing networking of the AR-Planar. During the evaluation no Internet connection was available. Thus, data transfer has to be performed with a USB stick.
    Add WiFi or UMTS Internet connection
     Post- processing
  The information about which difference between real world and model data belongs to a particular contractor’s responsibility is not provided by the system.
    Include contractor info
  Table 1. selection of identified issues during the field trial and solutions to those problems

resembled the traditional modus, where the professionals would compare paper-based blueprints and pictures against the architecture in front of them, pointing out certain aspects to each other and changing the point of view from time to time. With the Planar replacing the paper, they additionally took advantage of the AR display to pinpoint the building errors faster and document them. Most popular were the use of the pen, the transparency slider, and the sketching feature, which were not only used in the context of the building acceptance task itself, but in means of communication between the professionals as well. Examples are pointing gestures with the pen on the display surface or the circling of objects for easier reference during discussion. Thus a new layer of collaboration seemed to be added over the traditional process.
Overall, the professionals were very satisfied with the performance, as they tracked down numerous differences between the real world and the most recent model data. They were also able to instantly work with the user interface and needed only brief instructions on the handling of the tilt mechanisms of the AR camera and AR-Planar display.
However, they saw room for improvement with picture quality (especially contrast of video image) and the duration of the setup process, which largely determines the number of hotspots that can be examined during a day.
For the heuristic evaluation, the three professionals were given a list of general heuristics that are based on Nielsen’s 10 expert heuristics [19], slightly adapted to ARBA. A second list with the steps of the building acceptance process was used for a mental walkthrough. They were asked to match the general heuristics against each of the steps and to write down their findings. In a second iteration of the mental walkthrough, the professionals were given an extended list which contained a number of additional topics per step of the procedure that were of particular interest for us. The professionals were then asked to complete their findings.
The results of the evaluation are summarized in Table 1.
5 SYSTEM ERGONMOMICS STUDY
After the successful deployment of ARBA and the feedback of the heuristic evaluation, we were left with valuable insights about how to improve the system, but no knowledge about how well the AR-Planar compares in terms of usability to other AR system options for inspection tasks. That information would be valuable for the development of the next generation ARBA. So far, the choice of the AR-Planar was based mainly on considerations about battery life, processing power, invasiveness of interface, and extended use periods, in which a self-supported device obviously has advantages over a system that has to be carried by an operator.
We performed a user study that tries to balance between (a) finding an answer to the question “Which AR device for ARBA best matches the requirements found in the real application, concerning cost, availability, computational power etc.?” and (b) finding an answer to the question “Which AR device type for ARBA has the best usability in general?”. Rather than isolating individual factors such as display resolution or weight under otherwise idealized conditions, we chose a system level approach. Each chosen system represents an economically viable alternative for deploying ARBA. The test three systems all run a slightly modified version of the original ARBA software:
1. AR-Planar as described above
2. Head mounted display (HMD) and backpack system: We used
a Sony Glasstron D100BE (800x600, monoscopic) in video see-through mode from a head-mounted camera. Notebook computer and required peripherals were placed on a backpack.
Input was performed with a hand-held prop which contained a Qualisys tracking target for 6DOF input as well as a Gyromouse to steer the mouse pointer.
3. Ultramobile PC (UMPC): A Sony Vaio UX90 (Tablet PC, weight with camera ~1kg) with a 5” TFT display (800x480) with a camera and tracking target attached to its backplate were used. Interaction was performed with the touch screen (Figure 8).
5.1 Design and procedure
The competing systems were all using the same camera, the same tracking, the same intrinsic calibration parameters, and the same application software. Interaction with AR-Planar and UMPC was as described in section 3.2. HMD interaction was modified allowing for freehand placement of picked objects.
We were mainly interested in the usability of the interaction during the actual inspection task. A within-subject design was chosen, where 36 subjects consecutively tested all 3 conditions (i. e., devices). Each condition was tested by a subject in 3 different subtasks: (a) finding a difference between the CAD model and the real world structure (b) estimating the difference and (c) correcting the difference by moving the virtual object exactly to the position of its real-world counterpart (Figure 9). Between subjects the order of the devices and subtasks was randomized, while the order of displacements was kept constant.
Each subject started with a questionnaire asking for general information such as gender, age, etc. Afterwards, each subject was allowed time to familiarize him/herself with the first condition, followed by first condition. The test of the first condition ended with a usability questionnaire. The procedure was repeated for the other two conditions. At the end a final questionnaire asked the personal opinion of the subject about the best condition for each
Figure 8. the two conditions tested against the AR-Planar in the system ergonomics study: UMPC (left), HMD (right)
Figure 9. place of system ergonomics study (model, left) and example of misplaced object as seen out of the application, here a column made of concrete (right; highlighted yellow in left image)
    
selected results from the system ergonomics study; significant differences (P value < 0.05) are marked by an asterix; top part contains factors accessed by questionnaire, bottom part measured factors
subtask.
The usability questionnaire handed out at the end of each
condition consists of Davis’ ease of use questions [20] as well as some questions on the subjective performance of the subject.
The user study was conducted at Graz University of Technology in the Computer Science building, which resembles a factory hall in its architectural properties (Figure 9). Subjects were mostly university staff and students, and familiar with the building. The average age of the 36 subjects (6 female) was 29 years. Background skills were assessed using a scale from 1 (very experienced) to 5 (no experience), giving an average of 1.4 for general computer skills, 2.8 for 3D software and 3.0 for architecture.
5.2 Significant Findings
After a dimensional reduction two main factors were found: ease of use (Cronbach’s Alpha 0.936) and ergonomics (Cronbach’s Alpha 0.878). The latter includes questions such as whether the user would be able to use the condition all day long or whether the physical properties of the condition were well adapted to human beings.
The results can be seen in Table 2. The analysis of the one-per- condition questionnaires using a mixed GLM method reveals that concerning ease of use, UMPC and AR-Planar perform very similarly, while the HMD performs significantly worse on this scale. Looking at the question of ergonomics, AR-Planar performs better than UMPC and significantly better than HMD. UMPC performs significantly better than HMD.
Other questions in the one-per-condition questionnaire accessed properties of the individual interaction tasks: ease of selection of objects, ease of navigation, ease of distance estimation, and ease of object manipulation.
These results are supported by data we measured during the tests. One measure, ease of navigation, takes into account change of viewpoint and viewing angle per time unit. Here UMPC significantly outperformed HMD and AR-Planar with the HMD being even significantly better than AR-Planar.
5.3 Other Results
The other two measures, which were defined by the estimated/measured translational distance between the real object and the displaced/moved virtual object, showed no significances.
Interestingly, the ability to estimate differences was not significantly different between the conditions. Also, the results achieved within the positioning task did not show significances.
The evaluation of the post-test questionnaire revealed the following results: users voted with over 52% for UMPC as the preferred condition for the subtask of finding an object. HMD and AR-Planar could only convince 22% and 25% each of the users.
For the subtask of estimating the distance between real and virtual object, 64% voted for the AR-Planar, 28% for the UMPC and only 8% for the HMD. Resulting votes for the manipulation task look very similar to the distance estimation task: AR-Planar 61%, UMPC 25% and HMD 14%.
6 6.1
DISCUSSION AND FUTURE WORK ARBA
The AR-Planar running ARBA can be described as an operational prototype. The quality of the AR system was judged sufficient to safely discover deviations from the plan in case of missing or dispensable geometries. Objects displaced more than 20 cm can be accurately identified when staying within a certain working radius. The next version of ARBA, which is already in development, will be systematically tested in terms of precision. General improvements, such as a unified power source for all devices onboard the AR-Planar, or an on-screen keyboard have already been included.
The task of finding differences in the AR overlay could be further supported through improvement of displayed content. Most importantly, a higher quality camera can provide better contrast and resolution of the video image. Computer vision algorithms such as real-time contrast enhancement and edge enhancement may improve the quality of the video stream even further in case of poorly lit environments. Another idea is applying a moving virtual light source for creating artificial depth cues from dynamic shading.
A great potential for further optimization of ARBA using the AR-Planar lies in the emerging technology of markerless tracking. Without additional tracking equipment, the AR-Planar could be deployed within a few minutes. Even if factory halls seem to be difficult environments for markerless tracking because of high geometric complexity with poorly textured materials, there are some issues that could be exploited: most of the geometry is aligned with the main axes of the world coordinate system, and the application already includes a very complete model of the visual geometry, which could be used for model-based tracking.

6.2 Feedback from professionals
The heuristic evaluation revealed a large number of issues, but fortunately most of them are easily fixable. However, the professionals were very satisfied with the performance, as they tracked down numerous differences between the real world and the most recent model data, thereby saving a lot of money. They were also able to instantly work with the user interface, once the setup and startup procedures were complete. The only additional instructions needed concerned the handling of the tilt mechanisms of the AR camera.
The main concern is the efficiency of the setup process, which largely determines the number of hotspots that can be examined during a day.
6.3 The User Interface Question
While the outcome of the system ergonomics study is certainly not generalizable, we were able to obtain strong support for a number of theories that will guide the development of the next generation ARBA: it seems, that the UMPC is the best device when it comes to finding the differences between the real and virtual world. One possible explanation for this outcome could be the point-and-shoot metaphor that many users might know from digital cameras.
Also, while the AR-Planar does not require any force to be kept in place, it requires quite some force to be moved around for navigation; the situation is the reverse for the UMPC. While the UMPC is not suitable for using all day long in terms of weight and battery life, it can be easily carried to desired viewing points, and seems superior for through-the-lens navigation.
The HMD likely suffers from the fact that while movement is theoretically very easy, users move very slowly because of the added weight and because they are careful not to hit anything due to limited field of view and distortion of vision. Also hand-eye coordination without any support may be more difficult when using an HMD compared to the other conditions.
One possible explanation for the slightly worse results of the HMD in the distance estimation task could be the fact that users of AR-Planar and UMPC were able to look over their devices into the real world to put object magnitudes into better relation. The better performance of AR-Planar over UMPC is likely to display size. The larger display also supports collaboration better.
Overall, AR-Planar and UMPC each seem to have distinct advantages. A future plan is therefore to build an extended system which adds a retractable small display with affixed camera to the AR-Planar as a second screen so that both free-standing and handheld operation are possible.
7 CONCLUSION
In this paper we have discussed the use of AR for building acceptance and analyzed human factors and design approaches that are relevant for this application. We have presented the AR- Planar, a free-standing AR device which seems suitable for extended use in industrial environments. Field trials and user study results have revealed interesting findings concerning the ergonomics of operating AR devices in visual inspection tasks that can be expected to be valid beyond the specific application we are considering. The AR-Planar is also a very pragmatic design, suitable for a wide variety of real world situations and equipped with a user interface that aims to minimize the learning curve by building on established interface approaches.